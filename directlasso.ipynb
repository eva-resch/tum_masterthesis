{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is in here?\n",
    "\n",
    "* Simulation of data in 5 dimensions from a randomly created drift matrix $M$ and fixed volatility matrix $C=2*I_5$\n",
    "* Estimation of $M$ via the direct Lasso, implemented by hand\n",
    "* $\\textbf{Idea for simulation of data under a hard intervention using the conditional distribution}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import solve_continuous_lyapunov\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation\n",
    "\n",
    "### Setting\n",
    "We look at $X(t)\\in \\mathbb{R}^5$, meaning $p=5$, choose any $k\\in \\{1,2,3,4\\}$ and set $d = k/p$ as the edge probability, and define mean and standard deviation for the normal distribution.\n",
    "\n",
    "We choose to intervene on the first node, so $A={1}$.\n",
    "\n",
    "For every choice of matrices $M$ and $C$, we will generate $N=1000$ samples of the normal distribution, that solves the Lyapunov equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 5\n",
    "k = 1\n",
    "d = k / p\n",
    "mean = 0\n",
    "mean_vector = np.zeros(p)\n",
    "sd = 1\n",
    "intervention_set = [0]\n",
    "intervention_value = [3]\n",
    "N = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model drift matrix\n",
    "We model the drift matrix $M$ by setting $m_{ij}=\\omega_{ij}\\varepsilon_{ij}$ for $i\\neq j$ and the diagonal to $m_{ii}=-\\sum_{j\\neq i}\\lvert m_{ij}\\rvert - \\lvert\\varepsilon_{ii}\\rvert$ with $\\omega_{ij}\\sim \\text{Bernoulli}(d)$ and $\\varepsilon_{ij}\\sim \\mathcal{N}(0,1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1208)\n",
    "bernoulli_matrix = np.random.binomial(1, d, (p, p))\n",
    "normal_matrix = np.random.normal(mean, sd, (p, p))\n",
    "M = bernoulli_matrix * normal_matrix\n",
    "for i in range(p):\n",
    "    row_sum = np.sum(np.abs(M[i, :])) - np.abs(M[i, i])\n",
    "    M[i, i] = - row_sum - np.abs(normal_matrix[i,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Fix volatility matrix\n",
    "Choose $C=2*I_p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 2 * np.identity(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the Lyapunov equation\n",
    "Find the matrix $\\Sigma$ that solves the Lyapunov equation\n",
    "$$M \\Sigma + \\Sigma M^\\top + C = 0.$$\n",
    "***Attention:*** the algorithm solves the equation $M \\Sigma + \\Sigma M^\\top = C$ so we need the negative matrix $-C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma = solve_continuous_lyapunov(M, - C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create simulated data\n",
    "Generate $N=1000$ observations of a $p$-dimensional normal distribution with mean $0$ and covariance matrix $\\Sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1208)\n",
    "obs = np.random.multivariate_normal(mean = mean_vector, cov = Sigma, size = (N, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation\n",
    "\n",
    "Apply the Direct Lyapunov Lasso with $C = 2I_p$\n",
    "$$\\min_{M\\in\\mathbb{R}^{p x p}} \\frac{1}{2}\\lvert\\lvert M \\Sigma + \\Sigma M^\\top + C\\rvert\\rvert^2_F + \\lambda \\lvert\\lvert M \\rvert\\rvert _1$$\n",
    "with tuning parameter $\\lambda >0$ to estimate the matrix $M$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized M matrix:\n",
      " [[-2.52409569e+00 -1.09286092e-01 -1.00579715e-01 -9.75390365e-01\n",
      "   1.89575041e-08]\n",
      " [-3.58913772e-08 -4.73793618e-01 -6.02544348e-08 -9.88159796e-08\n",
      "   5.72808707e-10]\n",
      " [ 1.55075365e-09 -5.20588830e-02 -1.16758702e+00 -2.39869689e-08\n",
      "   1.21600291e-01]\n",
      " [-2.10671641e-01  6.56049098e-01  1.22445565e+00 -2.95201110e+00\n",
      "   4.21979991e-08]\n",
      " [ 3.43283033e-08  1.67226089e-05  1.94299250e-01  2.41587404e-08\n",
      "  -1.15631449e+00]]\n",
      "Objective function value: 1.32638995336986\n"
     ]
    }
   ],
   "source": [
    "lambda_val = 0.1\n",
    "\n",
    "def dll_objective(M_flat, Sigma, C, lambda_val, p) -> float:\n",
    "    M = M_flat.reshape((p, p))\n",
    "    frobenius_norm = 0.5 * np.linalg.norm(M @ Sigma + Sigma @ M.T + C, ord = 'fro') ** 2\n",
    "    l1_norm = np.sum(np.abs(M))\n",
    "    return frobenius_norm + lambda_val * l1_norm\n",
    "\n",
    "initial_M = - np.eye(p, p).flatten()\n",
    "\n",
    "result = minimize(dll_objective, initial_M, args=(Sigma, C, lambda_val, p), method='L-BFGS-B')\n",
    "M_optimized = result.x.reshape((p, p))\n",
    "print(\"Optimized M matrix:\\n\", M_optimized)\n",
    "print(\"Objective function value:\", result.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation of interventional data\n",
    "\n",
    "To generate samles from interventional data we need to sample from the conditional distribution. When we intervene on a subset $A\\subset [p]$ and set all the components to $X_A=x_A$, then we need to sample the rest of the vector $X_{-A}$ according to the conditional distribution with\n",
    "\n",
    "$$X_{-A}\\mid X_A=x_A \\sim \\mathscr{N}(\\mu_{-A} + \\Sigma_{-A,A}\\Sigma_{A,A}^{-1}(x_A-\\mu_A), \\Sigma_{-A,-A} - \\Sigma_{-A,A}\\Sigma_{A,A}^{-1}\\Sigma_{A,-A}).$$\n",
    "\n",
    "This procedure is done exemplary in the next code snippet (ChatGPT). Here, we call $-A$, the indices not in $A$, $B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interventional Sample:\n",
      "[ 3.         -2.478136   -0.14824914 -1.66732523  0.11513092]\n"
     ]
    }
   ],
   "source": [
    "# Partition the mean and covariance\n",
    "mean_vector_A = mean_vector[intervention_set]\n",
    "mean_vector_B = np.delete(mean_vector, intervention_set)\n",
    "Sigma_AA = Sigma[np.ix_(intervention_set, intervention_set)]\n",
    "Sigma_AB = Sigma[np.ix_(intervention_set, [i for i in range(p) if i not in intervention_set])]\n",
    "Sigma_BA = Sigma[np.ix_([i for i in range(p) if i not in intervention_set], intervention_set)]\n",
    "Sigma_BB = Sigma[np.ix_([i for i in range(p) if i not in intervention_set], [i for i in range(p) if i not in intervention_set])]\n",
    "\n",
    "# Compute the conditional mean and covariance for X_B | X_A = x_A\n",
    "conditional_mean = mean_vector_B + Sigma_BA @ np.linalg.inv(Sigma_AA) @ (intervention_value - mean_vector_A)\n",
    "conditional_cov = Sigma_BB - Sigma_BA @ np.linalg.inv(Sigma_AA) @ Sigma_AB\n",
    "\n",
    "# Sample X_B from the conditional distribution\n",
    "np.random.seed(1208)\n",
    "x_B = multivariate_normal.rvs(mean=conditional_mean, cov=conditional_cov)\n",
    "# x_B = np.random.multivariate_normal(mean = conditional_mean, cov = conditional_cov, size = (N, p-len(intervention_set)))\n",
    "\n",
    "# Combine X_A = x_A with the sampled x_B to get the full vector X\n",
    "x_interventional = np.empty(p)\n",
    "x_interventional[intervention_set] = intervention_value\n",
    "x_interventional[[i for i in range(p) if i not in intervention_set]] = x_B\n",
    "\n",
    "# Print the result\n",
    "print(\"Interventional Sample:\")\n",
    "print(x_interventional)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
